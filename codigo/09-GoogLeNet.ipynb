{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "supreme-privilege",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ITAM-DS/deep-learning/blob/master/codigo/08-VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compliant-soccer",
   "metadata": {
    "id": "grave-stake"
   },
   "outputs": [],
   "source": [
    "# !pip install -U d2l\n",
    "from d2l import tensorflow as d2l\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "danish-layout",
   "metadata": {
    "id": "fiscal-vegetation"
   },
   "outputs": [],
   "source": [
    "class Inception(tf.keras.Model):\n",
    "    # `c1`--`c4` are the number of output channels for each path\n",
    "    def __init__(self, c1, c2, c3, c4):\n",
    "        super().__init__()\n",
    "        # Path 1 is a single 1 x 1 convolutional layer\n",
    "        self.p1_1 = tf.keras.layers.Conv2D(c1, 1, activation='relu')\n",
    "        # Path 2 is a 1 x 1 convolutional layer followed by a 3 x 3\n",
    "        # convolutional layer\n",
    "        self.p2_1 = tf.keras.layers.Conv2D(c2[0], 1, activation='relu')\n",
    "        self.p2_2 = tf.keras.layers.Conv2D(c2[1], 3, padding='same',\n",
    "                                           activation='relu')\n",
    "        # Path 3 is a 1 x 1 convolutional layer followed by a 5 x 5\n",
    "        # convolutional layer\n",
    "        self.p3_1 = tf.keras.layers.Conv2D(c3[0], 1, activation='relu')\n",
    "        self.p3_2 = tf.keras.layers.Conv2D(c3[1], 5, padding='same',\n",
    "                                           activation='relu')\n",
    "        # Path 4 is a 3 x 3 maximum pooling layer followed by a 1 x 1\n",
    "        # convolutional layer\n",
    "        self.p4_1 = tf.keras.layers.MaxPool2D(3, 1, padding='same')\n",
    "        self.p4_2 = tf.keras.layers.Conv2D(c4, 1, activation='relu')\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        p1 = self.p1_1(x)\n",
    "        p2 = self.p2_2(self.p2_1(x))\n",
    "        p3 = self.p3_2(self.p3_1(x))\n",
    "        p4 = self.p4_2(self.p4_1(x))\n",
    "        # Concatenate the outputs on the channel dimension\n",
    "        return tf.keras.layers.Concatenate()([p1, p2, p3, p4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stable-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b1():\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, 7, strides=2, padding='same',\n",
    "                               activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adjusted-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b2():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, 1, activation='relu'),\n",
    "        tf.keras.layers.Conv2D(192, 3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "respected-tomato",
   "metadata": {
    "id": "clean-pulse"
   },
   "outputs": [],
   "source": [
    "def b3():\n",
    "    return tf.keras.models.Sequential([\n",
    "        Inception(64, (96, 128), (16, 32), 32),\n",
    "        Inception(128, (128, 192), (32, 96), 64),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "narrow-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b4():\n",
    "    return tf.keras.Sequential([\n",
    "        Inception(192, (96, 208), (16, 48), 64),\n",
    "        Inception(160, (112, 224), (24, 64), 64),\n",
    "        Inception(128, (128, 256), (24, 64), 64),\n",
    "        Inception(112, (144, 288), (32, 64), 64),\n",
    "        Inception(256, (160, 320), (32, 128), 128),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cross-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b5():\n",
    "    return tf.keras.Sequential([\n",
    "        Inception(256, (160, 320), (32, 128), 128),\n",
    "        Inception(384, (192, 384), (48, 128), 128),\n",
    "        tf.keras.layers.GlobalAvgPool2D(),\n",
    "        tf.keras.layers.Flatten()\n",
    "    ])\n",
    "# Recall that this has to be a function that will be passed to\n",
    "# `d2l.train_ch6()` so that model building/compiling need to be within\n",
    "# `strategy.scope()` in order to utilize the CPU/GPU devices that we have\n",
    "def net():\n",
    "    return tf.keras.Sequential([b1(), b2(), b3(), b4(), b5(),\n",
    "                                tf.keras.layers.Dense(10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "atomic-brass",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lovely-samoa",
    "outputId": "f8210a3e-8b68-4f13-9cbe-41bd7306fd37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t (1, 24, 24, 64)\n",
      "Sequential output shape:\t (1, 12, 12, 192)\n",
      "Sequential output shape:\t (1, 6, 6, 480)\n",
      "Sequential output shape:\t (1, 3, 3, 832)\n",
      "Sequential output shape:\t (1, 1024)\n",
      "Dense output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform(shape=(1, 96, 96, 1))\n",
    "for layer in net().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "competitive-resolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential Parameters:  3200 \t. Output shape:\t (1, 24, 24, 64)\n",
      "Sequential Parameters:  114944 \t. Output shape:\t (1, 12, 12, 192)\n",
      "Sequential Parameters:  552432 \t. Output shape:\t (1, 6, 6, 480)\n",
      "Sequential Parameters:  2809168 \t. Output shape:\t (1, 3, 3, 832)\n",
      "Sequential Parameters:  2487536 \t. Output shape:\t (1, 1024)\n",
      "Dense Parameters:  10250 \t. Output shape:\t (1, 10)\n",
      "------------------------------------------------------------\n",
      "Total parameters:  5977530\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform((1, 96, 96, 1))\n",
    "parameters = 0\n",
    "\n",
    "for layer in net().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, \"Parameters: \",  \n",
    "          np.sum([np.prod(p.shape) for p in layer.get_weights()]), \n",
    "          '\\t. Output shape:\\t', X.shape)\n",
    "    parameters += np.sum([np.prod(p.shape) for p in layer.get_weights()])\n",
    "\n",
    "print(\"--\"*30)\n",
    "print(\"Total parameters: \", parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "reflected-camping",
   "metadata": {
    "id": "recovered-latino"
   },
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 0.1, 10, 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-spotlight",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "```{markdown}\n",
    "1. ¿Cómo se compara el número de parámetros con modelos anteriores?\n",
    "2. ¿Cuál es el tamaño mínimo de imagen necesario para que el modelo implementado en este documento funcione?\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "08-VGG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
