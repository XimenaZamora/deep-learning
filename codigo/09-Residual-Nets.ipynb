{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tamil-bottle",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ITAM-DS/deep-learning/blob/master/codigo/08-VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "standard-error",
   "metadata": {
    "id": "grave-stake"
   },
   "outputs": [],
   "source": [
    "# !pip install -U d2l\n",
    "from d2l import tensorflow as d2l\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "usual-microphone",
   "metadata": {
    "id": "fiscal-vegetation"
   },
   "outputs": [],
   "source": [
    "class Residual(tf.keras.Model): \n",
    "    \"\"\"The Residual block of ResNet.\"\"\"\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            num_channels, padding='same', kernel_size=3, strides=strides)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            num_channels, kernel_size=3, padding='same')\n",
    "        self.conv3 = None\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = tf.keras.layers.Conv2D(\n",
    "                num_channels, kernel_size=1, strides=strides)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, X):\n",
    "        Y = tf.keras.activations.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3 is not None:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return tf.keras.activations.relu(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "obvious-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "raised-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_channels, num_residuals, first_block=False,\n",
    "                 **kwargs):\n",
    "        super(ResnetBlock, self).__init__(**kwargs)\n",
    "        self.residual_layers = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                self.residual_layers.append(\n",
    "                    Residual(num_channels, use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                self.residual_layers.append(Residual(num_channels))\n",
    "\n",
    "    def call(self, X):\n",
    "        for layer in self.residual_layers.layers:\n",
    "            X = layer(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "attended-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = ResnetBlock(64, 2, first_block=True)\n",
    "b3 = ResnetBlock(128, 2)\n",
    "b4 = ResnetBlock(256, 2)\n",
    "b5 = ResnetBlock(512, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "collaborative-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall that we define this as a function so we can reuse later and run it\n",
    "# within `tf.distribute.MirroredStrategy`'s scope to utilize various\n",
    "# computational resources, e.g. GPUs. Also note that even though we have\n",
    "# created b1, b2, b3, b4, b5 but we will recreate them inside this function's\n",
    "# scope instead\n",
    "def net():\n",
    "    return tf.keras.Sequential([\n",
    "        # The following layers are the same as b1 that we created earlier\n",
    "        tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same'),\n",
    "        # The following layers are the same as b2, b3, b4, and b5 that we\n",
    "        # created earlier\n",
    "        ResnetBlock(64, 2, first_block=True),\n",
    "        ResnetBlock(128, 2),\n",
    "        ResnetBlock(256, 2),\n",
    "        ResnetBlock(512, 2),\n",
    "        tf.keras.layers.GlobalAvgPool2D(),\n",
    "        tf.keras.layers.Dense(units=10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "written-talent",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lovely-samoa",
    "outputId": "f8210a3e-8b68-4f13-9cbe-41bd7306fd37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2D output shape:\t (1, 112, 112, 64)\n",
      "BatchNormalization output shape:\t (1, 112, 112, 64)\n",
      "Activation output shape:\t (1, 112, 112, 64)\n",
      "MaxPooling2D output shape:\t (1, 56, 56, 64)\n",
      "ResnetBlock output shape:\t (1, 56, 56, 64)\n",
      "ResnetBlock output shape:\t (1, 28, 28, 128)\n",
      "ResnetBlock output shape:\t (1, 14, 14, 256)\n",
      "ResnetBlock output shape:\t (1, 7, 7, 512)\n",
      "GlobalAveragePooling2D output shape:\t (1, 512)\n",
      "Dense output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform(shape=(1, 224, 224, 1))\n",
    "for layer in net().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "comfortable-james",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2D Parameters:  3200 \t. Output shape:\t (1, 112, 112, 64)\n",
      "BatchNormalization Parameters:  256 \t. Output shape:\t (1, 112, 112, 64)\n",
      "Activation Parameters:  0.0 \t. Output shape:\t (1, 112, 112, 64)\n",
      "MaxPooling2D Parameters:  0.0 \t. Output shape:\t (1, 56, 56, 64)\n",
      "ResnetBlock Parameters:  148736 \t. Output shape:\t (1, 56, 56, 64)\n",
      "ResnetBlock Parameters:  526976 \t. Output shape:\t (1, 28, 28, 128)\n",
      "ResnetBlock Parameters:  2102528 \t. Output shape:\t (1, 14, 14, 256)\n",
      "ResnetBlock Parameters:  8399360 \t. Output shape:\t (1, 7, 7, 512)\n",
      "GlobalAveragePooling2D Parameters:  0.0 \t. Output shape:\t (1, 512)\n",
      "Dense Parameters:  5130 \t. Output shape:\t (1, 10)\n",
      "------------------------------------------------------------\n",
      "Total parameters:  11186186.0\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform((1, 224, 224, 1))\n",
    "parameters = 0\n",
    "\n",
    "for layer in net().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, \"Parameters: \",  \n",
    "          np.sum([np.prod(p.shape) for p in layer.get_weights()]), \n",
    "          '\\t. Output shape:\\t', X.shape)\n",
    "    parameters += np.sum([np.prod(p.shape) for p in layer.get_weights()])\n",
    "\n",
    "print(\"--\"*30)\n",
    "print(\"Total parameters: \", parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "considered-cutting",
   "metadata": {
    "id": "recovered-latino"
   },
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 0.1, 10, 128\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=28)\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-exclusion",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "Tomado de la sección del [libro de texto](https://d2l.ai/chapter_convolutional-modern/resnet.html)\n",
    "\n",
    "```{markdown}\n",
    "1. Refer to Table 1 in the ResNet paper [He et al., 2016a] to implement different variants.\n",
    "2. In subsequent versions of ResNet, the authors changed the “convolution, batch normalization, and activation” structure to the “batch normalization, activation, and convolution” structure. Make this improvement yourself. See Figure 1 in [He et al., 2016b] for details.\n",
    "```\n",
    "[He et al., 2016b](https://arxiv.org/abs/1603.05027)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "08-VGG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
